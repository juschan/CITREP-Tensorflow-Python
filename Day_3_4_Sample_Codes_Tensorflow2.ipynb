{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_3_4_Sample_Codes_Tensorflow2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LUAaCFgMI1BF",
        "1sH7Cj5WKqoI",
        "3KA37_sbJHx2",
        "QrlPLfRA65Td",
        "TpKv4VWeZWuR",
        "lA4waja1-oM5",
        "_JS9mnQOAyID",
        "njdRT2vKMXjl"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uePIrjqGAJDw"
      },
      "source": [
        "# Topic 1 Overview of Machine Learning and Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTJ9sP3Yv1kl"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeTTuPEjwGcd"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-Bl6QjNwmS7"
      },
      "source": [
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GISVAwjU9PU-"
      },
      "source": [
        "# Topic 2 Basic Tensorflow Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS9iF4AwcWKt"
      },
      "source": [
        "## Tensor and Constant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAASVRkDjGse"
      },
      "source": [
        "a = tf.constant(4,dtype=tf.uint8)\r\n",
        "b = tf.constant(5.6,dtype=tf.float32)\r\n",
        "\r\n",
        "print(a)\r\n",
        "print(type(a))\r\n",
        "print(b)\r\n",
        "print(type(b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyx14UmSjt-Z"
      },
      "source": [
        "a = tf.constant(127,dtype=tf.int8)\r\n",
        "b = a+1\r\n",
        "c= b+1\r\n",
        "print(a)\r\n",
        "print(b)\r\n",
        "print(c)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLBI18if63u9"
      },
      "source": [
        "a = tf.constant(4,dtype=tf.float32)\n",
        "b = tf.constant(5.6,dtype=tf.float32)\n",
        "c = a*b\n",
        "print(c)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTlQoVy2lTS3"
      },
      "source": [
        "print(0.1)\r\n",
        "print(0.2)\r\n",
        "print(0.3)\r\n",
        "print(0.1+0.2)\r\n",
        "01.+0.2==0.3\r\n",
        "\r\n",
        "tol = 0.0001\r\n",
        "\r\n",
        "if abs((0.1+0.2)-0.3)< tol:\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLEytH1am9ZY"
      },
      "source": [
        "c.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqrTUMYs91II"
      },
      "source": [
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AwVhkzF9GJb"
      },
      "source": [
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Do6TJkdxNPp"
      },
      "source": [
        "a = tf.constant(4)\n",
        "b = tf.constant(5.6)\n",
        "print(a*b) #this doesn't work because each element in tensor must have same data type. https://www.tensorflow.org/guide/tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vSAnJip9r2g"
      },
      "source": [
        "a = tf.constant(4)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7BmWKDNTudj"
      },
      "source": [
        "a = tf.constant([1,5])\n",
        "a.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5YG9Zd4-ME2"
      },
      "source": [
        "a = tf.constant([1,5.0]) #tensor flow does casting\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKrdAfJm-jtL"
      },
      "source": [
        "#overflow\n",
        "a = tf.constant(255,dtype=tf.uint8)\n",
        "c = a+1\n",
        "print(a)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ntk8k09ceLy"
      },
      "source": [
        "## Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIag4x_q7vtK"
      },
      "source": [
        "a = tf.constant([[1,2],[3,4]])\n",
        "b = tf.constant([[5,6],[7,8]])\n",
        "c = tf.matmul(a,b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y62th6uynGE-"
      },
      "source": [
        "c.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agrGhqy3A294"
      },
      "source": [
        "d=tf.multiply(a,b)\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RLYPxjCcP2P"
      },
      "source": [
        "## Exercise: Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pem37r1W8rqj"
      },
      "source": [
        "x = tf.constant([[1.1,1.2]],dtype=tf.float32)\n",
        "w = tf.constant([[1,2],[3,4]],dtype=tf.float32)\n",
        "b = tf.constant([[2.3,2.5]],dtype=tf.float32)\n",
        "y = tf.matmul(x,w)+b\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU306MXBcZQU"
      },
      "source": [
        "## Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG-d_WXBnOOX"
      },
      "source": [
        "x = tf.Variable(0)\n",
        "x = tf.Variable(tf.zeros((2,2))) # 2 by 2 matrix, populated by zero\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOSyztU1ccDh"
      },
      "source": [
        "## Graph Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwXAmGocTydw"
      },
      "source": [
        "W = tf.Variable(tf.ones((2,2)),dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros((1,2)),dtype=tf.float32)\n",
        "\n",
        "@tf.function\n",
        "def nn(x):\n",
        "  y = tf.matmul(x,W)+b\n",
        "  return tf.nn.relu(y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S8WWf4prKhl"
      },
      "source": [
        "print(W)\r\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLlIdXpKpEP1"
      },
      "source": [
        "x = tf.constant([[1,0]],dtype=tf.float32)\n",
        "y = nn(x)\n",
        "y.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta0n4LpecmZb"
      },
      "source": [
        "## Gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT8qRcF2qAR3"
      },
      "source": [
        "x = tf.Variable(2.0)\n",
        "\n",
        "@tf.function\n",
        "def f(x):\n",
        "  return x**3 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP2L0o7cTozu"
      },
      "source": [
        "with tf.GradientTape() as g:  # context manager\n",
        " y = f(x)\n",
        "dy_dx = g.gradient(y,x)\n",
        "dy_dx.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS9IJlJaMaT7"
      },
      "source": [
        "# Topic 3 Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE7Rj815AXks"
      },
      "source": [
        "## MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDLY4X1_1P5o"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZhCnZfoQ4tu"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH2fG4SuFlh3"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wZ4aCPMGKLU"
      },
      "source": [
        "print(y_train[0:5]) #check with images later"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpVY92-iGeqA"
      },
      "source": [
        "print(x_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGIJa7-5FsuB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(y_train[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IWFB2XTDGQs"
      },
      "source": [
        "#### One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAZ0Lq1rC4dl"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train,y_test = to_categorical(y_train), to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGygRlV2DDCS"
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWGuG5ilC-XI"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eFpPIeZAabY"
      },
      "source": [
        "## Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF3AKWVcHiQv"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_ofmYg-FupD"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbHR8Io2JvQI"
      },
      "source": [
        "print(y_train[0:5]) #label encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9cXEWr9HuXo"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxDTlmbiHx7s"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N49NrPlcAddg"
      },
      "source": [
        "## CIFAR dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-rlfCm-I4AW"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE0eKCG8Fzic"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qxeCieqKDlX"
      },
      "source": [
        "print(y_train[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap22osu2KY4M"
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXILK8u9Jbdi"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(class_names[y_train[i][0]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoC6dbd2bRKA"
      },
      "source": [
        "## IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9wjPq4lbUOL"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print(x_train[0])\n",
        "print(\"length of x_train[0]\", len(x_train[0]))\n",
        "\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVEOPEODLSYA"
      },
      "source": [
        "dt = imdb.load_data()\n",
        "dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmLtSzOILSV3"
      },
      "source": [
        "print(x_train[0])\n",
        "print(\"length of x_train[0]\", len(x_train[0])) #truncate by taking the last 80 elements."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKgjQ1Cp3ck2"
      },
      "source": [
        "# Topic 4 Neural Networks for Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1WP-Y6cTHOJ"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NklScv9T4Qin"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz4jud2JtHeq"
      },
      "source": [
        "dataset = dataset.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OncfSUNz1CE"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEnw4DOK4paU"
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXyFJ7xAQz6r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYvoPukJzf37"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyf4b2peeaIx"
      },
      "source": [
        "y_train = x_train.pop('medv')\n",
        "y_test = x_test.pop('medv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVgYIyMfpFT2"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9p5Xxxr7OUK"
      },
      "source": [
        "#x_train = (x_train - x_train.mean())/(x_train.max()-x_train.min()) # minmax scaler\n",
        "#x_test = (x_test - x_test.mean())/(x_test.max()-x_test.min()) #not a good practice, should use train set parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cjIRT24QKKS"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled=scaler.fit_transform(x_train)\n",
        "x_test_scaled=scaler.transform(x_test) #min-max scale on x_test, but use the parameters from x_train\n",
        "x_train_scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYHoIlOnTOIx"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0icWR2jozrFQ"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbOpuGY8zzZe"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64,activation='relu',input_shape=[len(x_train.keys())]))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWrzUGqBShII"
      },
      "source": [
        "print([x_train.keys()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nT2BAqZ1bgn"
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(lr=0.001) # RMSprop: Divide the gradient by a running average of its recent magnitude; Refer to keras doc. learning rate is parameter.\n",
        "model.compile(loss='mse',optimizer=optimizer,metrics=['mae', 'mse']) #mae: mean absolute error; #mse: mean squared error;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui4mp-xbQnch"
      },
      "source": [
        "model.summary() # (13+)*64+64=896; 64*64+64=4160 (64 bias terms); 64+1 (bias term) = 65"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEDNJSdIj3kJ"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(64,activation='relu',input_shape=[len(x_train.keys())]),\n",
        "    Dense(64,activation='relu'),\n",
        "    Dense(1,activation='linear')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPcfBK55AY6r"
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(lr=0.001)\n",
        "model.compile(loss='mse',optimizer=optimizer,metrics=['mae', 'mse'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcm28BDZxmte"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sQQ0-OwJGV5"
      },
      "source": [
        "### Visualize the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfWmmre_Gxvn"
      },
      "source": [
        "keras.utils.plot_model(model, 'my_first_model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_JTBz0UG7Uk"
      },
      "source": [
        "keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Q-M1B6TUoS"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaEA22PM7u-c"
      },
      "source": [
        "EPOCHS = 100\n",
        "history = model.fit(x_train, y_train,epochs=EPOCHS,shuffle=True, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNHRRuO5Taiu"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHuFHb-u1u1I"
      },
      "source": [
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae'] #validation_mae, in this case, it is test data.\n",
        "epoch = range(len(mae))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,mae,label='mae')\n",
        "plt.plot(epoch,val_mae,label='val_mae')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error [MPG]')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eiSHvsoS75G"
      },
      "source": [
        "loss, mae, mse = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Testing Mean Abs Error: {:5.2f}\".format(mae))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0t-WVkCUb6S"
      },
      "source": [
        "### Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2WGbmq8Txjo"
      },
      "source": [
        "y_hat = model.predict(x_test).flatten()\n",
        "\n",
        "plt.scatter(y_test, y_hat)\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hi9pgiAb_Wc"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "### Save the Model in HDF5 Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIn_PdWVYWUy"
      },
      "source": [
        "model.save(\"regression.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj0_-g09jL-S"
      },
      "source": [
        "### Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqTRRcZPv8WF"
      },
      "source": [
        "new_model = keras.models.load_model('regression.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbl5w8vDjTwU"
      },
      "source": [
        "### Save the Model in SavedModel Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8THLTbmwGa4"
      },
      "source": [
        "model.save(\"regression/1/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRIuYbSdwoUr"
      },
      "source": [
        "new_model = keras.models.load_model('regression/1/')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfhIrE2fDRDv"
      },
      "source": [
        "### Save and Load Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFhivcJ8DDXZ"
      },
      "source": [
        "# Save the weights\n",
        "model.save_weights('./regression/1/w')\n",
        "\n",
        "# Restore the weights\n",
        "model.load_weights('./regression/1/w)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VgV9NCaZxUb"
      },
      "source": [
        "### Exercise: Predictive Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i576kB-VZwft"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"                \n",
        "dataset = pd.read_csv(dataset_path, names=[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\", \"Name\"])\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j5Bikh8aUVr"
      },
      "source": [
        "dataset = dataset.dropna()\n",
        "dataset.pop('Name')\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxJQ5K88agh9"
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xTPXgMaauPD"
      },
      "source": [
        "y_train = x_train.pop('SepalWidth')\n",
        "y_test = x_test.pop('SepalWidth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_IJ8nckaiFJ"
      },
      "source": [
        "x_train = (x_train - x_train.min())/(x_train.max()-x_train.min())\n",
        "x_test = (x_test - x_test.min())/(x_test.max()-x_test.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Gy30k0JKE_"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaT3T4R5a79X"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSDblFbWa_rX"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64,activation='relu',input_shape=[len(x_train.keys())]))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFFp6-9EbMj4"
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(lr=0.001)\n",
        "model.compile(loss='mse',optimizer=optimizer,metrics=['mae', 'mse'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JATAjHErbRNw"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja3XlvETbGDh"
      },
      "source": [
        "EPOCHS = 100\n",
        "history = model.fit(x_train, y_train,epochs=EPOCHS,shuffle=True, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCkUA2yabWRM"
      },
      "source": [
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "epoch = range(len(mae))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,mae,label='mae')\n",
        "plt.plot(epoch,val_mae,label='val_mae')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error [MPG]')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS7xuGFMbfXf"
      },
      "source": [
        "loss, mae, mse = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Testing Mean Abs Error: {:5.2f}\".format(mae))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxSqoBm8bkIN"
      },
      "source": [
        "y_hat = model.predict(x_test).flatten()\n",
        "\n",
        "plt.scatter(y_test, y_hat)\n",
        "plt.xlabel('True Values [Sepal Width]')\n",
        "plt.ylabel('Predictions [Sepal Width]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekRk7I90dvSa"
      },
      "source": [
        "y_hat = model.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV5IJg197lM8"
      },
      "source": [
        "model.save(\"iris.h5\")\n",
        "\n",
        "# tf.saved_model.save(model, \"/model_iris/1/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhx2FdHzubCt"
      },
      "source": [
        "new_model = keras.models.load_model('iris.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdfphVHCuhmb"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kFBAGkA97hH"
      },
      "source": [
        "# Topic 5 Neural Network for Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuR1qtSVAu1a"
      },
      "source": [
        "## NN Demo on MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNtyZurvwcbF"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V0RpO3tw000"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D41u9e5ZykId"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFfmbYnE7gpX"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Fe_T99zIWG"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi5DBbv-Hwy-"
      },
      "source": [
        "import datetime as datetime\n",
        "# Tensorflow Board\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/scalars\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(mylogdir, histogram_freq=1)\n",
        "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQI2tECjzkvp"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test), callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWe-1joB0A-S"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKFgWbY_7Px0"
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uVDPhv-7op-"
      },
      "source": [
        "model.save(\"mnist.h5\")\n",
        "\n",
        "# tf.saved_model.save(model, \"/model_mnist/1/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RcuaHhkt7c6"
      },
      "source": [
        "new_model =keras.models.load_model('mnist.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mud-twRruHwK"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGzjGBNsD2Zn"
      },
      "source": [
        "#### Sparse Cross Entropy vs Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXVRqVznDxZ7"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzeVX4k9D9gq"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train,y_test = to_categorical(y_train), to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPm1x4pvEIXP"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB0iNKOjELa2"
      },
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)), #flattens input\n",
        "    Dense(64,activation='relu'),\n",
        "    Dense(32,activation='relu'),\n",
        "    Dense(10,activation='softmax')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0C8r5X3EuBU"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZVctmXmEz_6"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZOBUJ02-rA9"
      },
      "source": [
        "## Ex: Classification for Fashsion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwcNE9URCjSD"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHUqKhYpgKXW"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzgrzqfvCrFW"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIVFlrswCvds"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epAIFevbCzCc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7inRenTUC2Ug"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L_8D8ooDYeg"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tEK_zvGDb9k"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGRt60Z5Deqy"
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLGfwYKYDggP"
      },
      "source": [
        "model.save(\"classifcation_model_fashion_mnist.h5\")\n",
        "\n",
        "#tf.saved_model.save(model, \"/model_fashion_mnist/1/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr7i2L08IIp5"
      },
      "source": [
        "# Topic 6 Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvht4o67PiUU"
      },
      "source": [
        "## CNN on MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvnz7eV2A8LN"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxkstCCRxz-1"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOAh91fYFIii"
      },
      "source": [
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndIDOO30NRkt"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PumM6VQbBKYv"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(28, 28,1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9s56hLvCyi8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "haowsN8SB5gY"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xlKtXNM2g3fz"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n2aSUHUah_m0"
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wEuxiX_j56O"
      },
      "source": [
        "## Ex: CNN on CIFAR dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN_Ku2X91WlQ"
      },
      "source": [
        "### Import and Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QkcKtFik0guh"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VYdyIB5_FENe"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPXFAwUl1b5V"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_7ApD3saz-4b"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    #Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ls6o4nOMU10P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PKwQJWPG0CB4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgQGI9_41fSJ"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gcEp0NcN0RBs"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY6tbfDe1j3k"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l3dRs4J6jNMN"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JlJ9Xvoa1D-P"
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgViJ2IO1ndb"
      },
      "source": [
        "## CNN on Small Dataset: Cats and Dogs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD3qK9B4liVT"
      },
      "source": [
        "### Import the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-GVgi54-2gk2"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i02EGsya2lEb"
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A1AEjiplHH1w"
      },
      "source": [
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_HtDXZUW2tpB"
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "50UcL1Cw2tlZ"
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tWW-TrLWHUXn"
      },
      "source": [
        "print(train_cats_dir)\n",
        "print(train_dogs_dir)\n",
        "print(validation_cats_dir)\n",
        "print(validation_dogs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BwsapX6j22ET"
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEpIw2V0lmGF"
      },
      "source": [
        "### Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GCQqwvi4270h"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TtOhb7kR3AC4"
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h0uVoHIQ3DbG"
      },
      "source": [
        "#Does resizing for target_size\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO3WCmo2nB-Q"
      },
      "source": [
        "### Visualize the raw images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IMONiajb3N-y"
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PSpOtG-O3P-k"
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wkKcszhEm-KR"
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1vHLHUmUId"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d7r_aTsV3TMV"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNCS7L2amtYn"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cG2URME73ePz"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val//batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av71E0Qcnwon"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gY2A6qRw3hee"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkEPDE4CrSsf"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAALUD0-rmfJ"
      },
      "source": [
        "#### Flipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yQyFpPyD3haA"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yu86mPQO3yDW"
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ccQ-PHze30HY"
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0xffOmUy32B4"
      },
      "source": [
        "# Re-use the same custom plotting function defined and used\n",
        "# above to visualize the training images\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbWPTnTarthk"
      },
      "source": [
        "#### Rotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QltWM5Tl39FD"
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PiAxHpDx39yX"
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jxBavO0o3_m0"
      },
      "source": [
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itVuzyJZrzVR"
      },
      "source": [
        "#### Zoom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JkMC0CoJ4Bwe"
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7WuP6qZy5R1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "713vYmsB4HaU"
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M2cdcwLT4Ieq"
      },
      "source": [
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6mpaNGixeDu"
      },
      "source": [
        "### Applying Data Augumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OkyUlE-g4KN6"
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TBNK6kzB4Nrw"
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jSY-00oU4SCW"
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A0_cFKmb4T8B"
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aztdvJ9S4Vm_"
      },
      "source": [
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRck3uIwyeLo"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1QU9CT1u4WYH"
      },
      "source": [
        "model_new = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu',  input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WZu27Lx7yqPg"
      },
      "source": [
        "model_new.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6naCWJHxygNk"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zWN9-NfR4Z5y"
      },
      "source": [
        "model_new.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eXoQV63m4cQ_"
      },
      "source": [
        "history = model_new.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val//batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4eKE0nEyxfk"
      },
      "source": [
        "### Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xTVpfC2X4erj"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMaVg1zTKCIG"
      },
      "source": [
        "## Ex: CNN with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HkCujaTvKBAK"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QLW6dO7GLStl"
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tIHWdyGHMEE1"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qOtX3gyCMb_2"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLlwee1LY0CA"
      },
      "source": [
        "# Topic 7 Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oftG5ka_YMyS"
      },
      "source": [
        "## Text Classification With RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEmqPrAWa75W"
      },
      "source": [
        "### Load the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a6eJ1XvJYREL"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tZ-97-pcFIW"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s62nbYQoY5Bz"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow. keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3zsYEhS39A8Z"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm-q7PEUcqbM"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N8MPZorXZFhp"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zYXl4jvCZH-N"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size,epochs=15,validation_data=(x_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTcnxwuMdWST"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8BKGm4fumhlb"
      },
      "source": [
        "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
        "score, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zwp6F2TQZNN7"
      },
      "source": [
        "loss = model.history['loss']\n",
        "val_loss = model.history['val_loss']\n",
        "acc = model.history['acc']\n",
        "val_acc = model.history['val_acc']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K0jWGjHQCk4"
      },
      "source": [
        "## Ex: RNN on MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PV0teW8pP9LZ"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RqMvhB4IQTCV"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(128, activation='relu',input_shape=(28,28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zI7oqdHOR_Z9"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7WIKSUtOSlzg"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhDR8jvnS1Fl"
      },
      "source": [
        "## Stack RNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x3BbukOIIOrI"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aPAGD1EMSp31"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(32, activation='relu',input_shape=(28,28),return_sequences=True),\n",
        "    LSTM(32, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9tdU-srS30W"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QWl1iR1uS7Fn"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt8tuJzrOCUK"
      },
      "source": [
        "## Bidirectional RNN Architecuture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BfTEzsstIQw5"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Veyr1wElHTqa"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(32, activation='relu',input_shape=(28,28))),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ibySHAOoIAvJ"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1OccE5KN7aS"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HeWq_7zY6oh"
      },
      "source": [
        "# Topic 8 Transfer Learning & Tensorflow Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_aEYm4PVptX"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6b5TlezSh4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow. keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5oFy8mPzroV"
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False) \n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) \n",
        "x=Dense(1024,activation='relu')(x) \n",
        "x=Dense(512,activation='relu')(x) \n",
        "preds=Dense(1,activation='sigmoid')(x) \n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0G65Lqr0M1_"
      },
      "source": [
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdBrPCbT01fP"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLg258YE09am"
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr_nO92c1ZR1"
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmbjR6ar2Fdo"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AliO7-3ZVY0R"
      },
      "source": [
        "#### Test the Dog Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_HxRBW0aGd"
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "\n",
        "#img = tf.keras.utils.get_file('image.jpg','https://images.all-free-download.com/images/graphicthumb/dogs_dog_animal_215598.jpg')\n",
        "#img = tf.keras.utils.get_file('image2.jpg','https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/friendliest-dog-breeds-golden-1578596627.jpg')\n",
        "#img=tf.keras.utils.get_file('image3.jpg', 'https://upload.wikimedia.org/wikipedia/commons/7/73/Lion_waiting_in_Namibia.jpg')\n",
        "img=tf.keras.utils.get_file('image.jpg', 'https://www.google.com/url?sa=i&url=https%3A%2F%2Ftime.com%2F43758%2Fhuman-faces-can-express-at-least-21-distinct-emotions%2F&psig=AOvVaw3pJ1Iv7W8JZfTK4Dh5tetu&ust=1600412923735000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCJip7PHQ7-sCFQAAAAAdAAAAABAD')\n",
        "img = Image.open(img).resize((150,150))\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h26GlSSs6Ima"
      },
      "source": [
        "img = np.array(img)/255.0\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtEBS8n76MlD"
      },
      "source": [
        "result = model.predict(img[np.newaxis, ...])\n",
        "result\n",
        "# round(result[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-47kHmeg7yed"
      },
      "source": [
        "x1 = img[np.newaxis, ...]\n",
        "x1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbBe5fqIVcdS"
      },
      "source": [
        "#### Test the Cat Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG5RKBIT7isb"
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "\n",
        "#img = tf.keras.utils.get_file('image4.jpg','https://images.all-free-download.com/images/graphicthumb/cat_with_green_eyes_194623.jpg')\n",
        "img = tf.keras.utils.get_file('image101.jpg','https://i0.wp.com/cdn-prod.medicalnewstoday.com/content/images/articles/313/313264/african-face.jpg?w=1155&h=1104')\n",
        "img = Image.open(img).resize((150,150))\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raRlK-t66dOI"
      },
      "source": [
        "img = np.array(img)/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hGOKuAB6gQI"
      },
      "source": [
        "result = model.predict(img[np.newaxis, ...])\n",
        "result[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRJT2KYRVlyB"
      },
      "source": [
        "## Tensorflow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R22VeyXPY-8e"
      },
      "source": [
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIk0CekhlsHR"
      },
      "source": [
        "classifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMG-n_jLlvIQ"
      },
      "source": [
        "classifier = tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=(224,224,3))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUVxJm8l2jd"
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "\n",
        "img = tf.keras.utils.get_file('image.jpg','https://images.all-free-download.com/images/graphicthumb/dogs_dog_animal_215598.jpg')\n",
        "img = Image.open(img).resize((224,224))\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQSl-wurl_qd"
      },
      "source": [
        "img = np.array(img)/255.0\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IUdLD3qmDN0"
      },
      "source": [
        "result = classifier.predict(img[np.newaxis, ...])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5aXZwDOmJ_g"
      },
      "source": [
        "predicted_class = np.argmax(result[0], axis=-1)\n",
        "predicted_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB6dcirZmNUN"
      },
      "source": [
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aKz3mPpmRj0"
      },
      "source": [
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "predicted_class_name = imagenet_labels[predicted_class]\n",
        "_ = plt.title(\"Prediction: \" + predicted_class_name.title())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPbEOo5dSvp4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8M-eZxlU1Ql"
      },
      "source": [
        "# (Optional) Topic 9 Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa5s4rd3IpNy"
      },
      "source": [
        "## Sequential Model as Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUAaCFgMI1BF"
      },
      "source": [
        "### MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrNY6GDlGrOk"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMTwwfxODzgL"
      },
      "source": [
        "def nn_model():\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(32, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xu-UJ6WGZrO"
      },
      "source": [
        "model = nn_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR_NW9NRI3-t"
      },
      "source": [
        "### Fashion MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPG2wYABIeUd"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMoXxUYzImXE"
      },
      "source": [
        "model = nn_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbAOV2fSHd0C"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdDpxaSUHPHF"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sH7Cj5WKqoI"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slskr_9aKosJ"
      },
      "source": [
        "def nn_model(lr):\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(32, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    optimizer = tf.keras.optimizers.Adam(lr)\n",
        "    model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeTMXtfcKtML"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "lr = [0.001,0.01,0.1]\n",
        "acc=[]\n",
        "for i in lr:\n",
        "    model = nn_model(i)\n",
        "    model.fit(x_train,y_train,verbose=0)\n",
        "    loss,accuracy = model.evaluate(x_test,y_test)\n",
        "    acc.append(accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOvs7A5KK50d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.semilogx(lr,acc)\n",
        "plt.semilogx(lr,acc,'o')\n",
        "plt.xlabel('learning rate')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KA37_sbJHx2"
      },
      "source": [
        "## Layers as Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC3WniIUU44L"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(784,), name='img')\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cCrFyG_VQCF"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSFaihMIVk6g"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=keras.optimizers.RMSprop(),metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=5,validation_data=(x_test,y_test))\n",
        "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Test loss:', test_scores[0])\n",
        "print('Test accuracy:', test_scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubArRQLVZFQ_"
      },
      "source": [
        "model.save('model.h5')\n",
        "del model\n",
        "# Recreate the exact same model purely from the file:\n",
        "model = keras.models.load_model('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrlPLfRA65Td"
      },
      "source": [
        "###Ensembling with Nested Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKjxR7nr64Mr"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model():\n",
        "  inputs = keras.Input(shape=(128,))\n",
        "  outputs = layers.Dense(1, activation='sigmoid')(inputs)\n",
        "  return keras.Model(inputs, outputs)\n",
        "\n",
        "model1 = get_model()\n",
        "model2 = get_model()\n",
        "model3 = get_model()\n",
        "\n",
        "inputs = keras.Input(shape=(128,))\n",
        "y1 = model1(inputs)\n",
        "y2 = model2(inputs)\n",
        "y3 = model3(inputs)\n",
        "outputs = layers.average([y1, y2, y3])\n",
        "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ureVFSbwIj3J"
      },
      "source": [
        "keras.utils.plot_model(ensemble_model, 'model.png')\n",
        "# keras.utils.plot_model(model, 'model.png', show_shapes=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpKv4VWeZWuR"
      },
      "source": [
        "### Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSeutphmZWDF"
      },
      "source": [
        "from tensorflow.keras import layers \n",
        "encoder_input = keras.Input(shape=(28, 28, 1), name='original_img')\n",
        "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
        "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
        "encoder.summary()\n",
        "\n",
        "decoder_input = keras.Input(shape=(16,), name='encoded_img')\n",
        "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
        "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
        "x = layers.UpSampling2D(3)(x)\n",
        "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "autoencoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2aDe2yOJ_dX"
      },
      "source": [
        "keras.utils.plot_model(autoencoder, 'model.png')\n",
        "# keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA4waja1-oM5"
      },
      "source": [
        "### Toy Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WlidFV2-lW-"
      },
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3), name='img')\n",
        "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "block_1_output = layers.MaxPooling2D(3)(x)\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
        "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "block_2_output = layers.add([x, block_1_output])\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_2_output)\n",
        "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "block_3_output = layers.add([x, block_2_output])\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation='relu')(block_3_output)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs, name='toy_resnet')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb2XVAkH-vGR"
      },
      "source": [
        "keras.utils.plot_model(model, 'mini_resnet.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIWAMHB5-2iA"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=64,\n",
        "          epochs=1,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSocWTHHAMxR"
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JS9mnQOAyID"
      },
      "source": [
        "### Multiple Inputs and Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbI8q4kcAd55"
      },
      "source": [
        "num_tags = 12  # Number of unique issue tags\n",
        "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
        "num_departments = 4  # Number of departments for predictions\n",
        "\n",
        "title_input = keras.Input(shape=(None,), name='title')  # Variable-length sequence of ints\n",
        "body_input = keras.Input(shape=(None,), name='body')  # Variable-length sequence of ints\n",
        "tags_input = keras.Input(shape=(num_tags,), name='tags')  # Binary vectors of size `num_tags`\n",
        "\n",
        "# Embed each word in the title into a 64-dimensional vector\n",
        "title_features = layers.Embedding(num_words, 64)(title_input)\n",
        "# Embed each word in the text into a 64-dimensional vector\n",
        "body_features = layers.Embedding(num_words, 64)(body_input)\n",
        "\n",
        "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
        "title_features = layers.LSTM(128)(title_features)\n",
        "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
        "body_features = layers.LSTM(32)(body_features)\n",
        "\n",
        "# Merge all available features into a single large vector via concatenation\n",
        "x = layers.concatenate([title_features, body_features, tags_input])\n",
        "\n",
        "# Stick a logistic regression for priority prediction on top of the features\n",
        "priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(x)\n",
        "# Stick a department classifier on top of the features\n",
        "department_pred = layers.Dense(num_departments, activation='softmax', name='department')(x)\n",
        "\n",
        "# Instantiate an end-to-end model predicting both priority and department\n",
        "model = keras.Model(inputs=[title_input, body_input, tags_input],\n",
        "                    outputs=[priority_pred, department_pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u8nLBvYAgjf"
      },
      "source": [
        "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njdRT2vKMXjl"
      },
      "source": [
        "## Ex: Funcational API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWWaseitMMrR"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3), name='img')\n",
        "\n",
        "x = layers.Conv2D(32,(3,3), activation='relu',padding='same')(inputs)\n",
        "x = layers.Conv2D(64,(3,3), activation='relu',padding='same')(x)\n",
        "y1 = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "x = layers.Conv2D(16,(3,3), activation='relu',padding='same')(inputs)\n",
        "x = layers.Conv2D(32,(3,3), activation='relu',padding='same')(x)\n",
        "x = layers.Conv2D(64,(3,3), activation='relu',padding='same')(x)\n",
        "y2 = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "y3 = layers.concatenate([y1, y2])\n",
        "y4 = layers.Flatten()(y3)\n",
        "y5 = layers.Dense(128,activation='softmax')(y4)\n",
        "outputs = layers.Dense(10,activation='softmax')(y5)\n",
        "\n",
        "model = keras.Model(inputs, outputs, name='dual_cnn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu4U1MieNOhq"
      },
      "source": [
        "# keras.utils.plot_model(model, 'model.png')\n",
        "keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUsqhsi5VFhN"
      },
      "source": [
        "# (Optional) Topic 10 TF.Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M6_rRCbVHfN"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jakQg7RzVPip"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFnqG3iNVZ4W"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEvvRYR5VheN"
      },
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E3hkgT4VsI5"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VGIkDDIWCeI"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5v6-r9YWHgz"
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AaTSrCnWNjc"
      },
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNlHlL_2WQt3"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "  print(template.format(epoch+1,\n",
        "                        train_loss.result(),\n",
        "                        train_accuracy.result()*100,\n",
        "                        test_loss.result(),\n",
        "                        test_accuracy.result()*100))\n",
        "\n",
        "  # Reset the metrics for the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6kWWwmhWV8R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}